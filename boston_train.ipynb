{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "clean_data = pd.read_csv('/Users/ioanahritcu/Documents/Projects/boston housing/data/boston_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, clean_data['MEDV'], test_size=0.25, random_state=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "l_regression = LinearRegression()\n",
    "trained_model = l_regression.fit(X_train, y_train)\n",
    "y_train_predict = l_regression.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_predict)))\n",
    "r2 = r2_score(y_train, y_train_predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 1.8210269358786414e-14\n",
      "R2 score is 1.0\n",
      "MAE score is 1.4612592093050016e-14\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = l_regression.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_predict)))\n",
    "r2 = r2_score(y_train, y_train_predict)\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print('MAE score is {}'.format(mean_absolute_error(y_train, y_train_predict)))\n",
    "# model evaluation for testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 1.9108636347594685e-14\n",
      "R2 score is 1.0\n",
      "MAE scors is 1.550340704956235e-14\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = l_regression.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "r2 = r2_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print('MAE scors is {}'.format(mean_absolute_error(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# retrain with all data and save model\n",
    "all_data = scaler.fit_transform(clean_data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data_model = l_regression.fit(all_data, clean_data['MEDV'])\n",
    "all_data_model_predict = l_regression.predict(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth()           \n",
    "drive = GoogleDrive(gauth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #upload files to google drive\n",
    "\n",
    "# upload_file_list = ['metrics.txt']\n",
    "# for upload_file in upload_file_list:\n",
    "# \tgfile = drive.CreateFile({'parents': [{'id': '1qgOzoq9yZX8uq93s51q5cPLjBzeZhfrK'}]})\n",
    "# \t# Read file and set it as the content of this instance.\n",
    "# \tgfile.SetContentFile(upload_file)\n",
    "# \tgfile.Upload() # Upload the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #download files from google drive\n",
    "\n",
    "# for i, file in enumerate(sorted(file_list, key = lambda x: x['title']), start=1):\n",
    "# \tprint('Downloading {} file from GDrive ({}/{})'.format(file['title'], i, len(file_list)))\n",
    "# \tfile.GetContentFile(file['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Create a GoogleDriveFile instance with title 'test.txt'.\n",
    "# file1 = drive.CreateFile({'parents': [{'id': '1cIMiqUDUNldxO6Nl-KVuS9SV-cWi9WLi'}],'title': 'test.txt'})  \n",
    "# # Set content of the file from the given string.\n",
    "# file1.SetContentString('Hello World!') \n",
    "# file1.Upload()\n",
    "\n",
    "# # see files in google drive\n",
    "# file2 = drive.CreateFile({'id': file1['id']})\n",
    "# file2.GetContentString('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 13)\n",
      "(490,)\n"
     ]
    }
   ],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "\n",
    "TargetVariable='MEDV'\n",
    "Predictors=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "\n",
    "X=clean_data[Predictors].values\n",
    "y=clean_data[TargetVariable].values\n",
    "\n",
    "# Selecting the final set of predictors for the deployment\n",
    "\n",
    "\n",
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Choose between standardization and MinMAx normalization\n",
    "#PredictorScaler=StandardScaler()\n",
    "PredictorScaler=MinMaxScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "\n",
    "# Generating the standardized values of X\n",
    "X=PredictorScalerFit.transform(X)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file of Predictive Model is saved at Location: /Users/ioanahritcu/Documents/Projects/boston housing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Saving the Python objects as serialized files can be done using pickle library\n",
    "# Here let us save the Final model\n",
    "with open('Final_Model.pkl', 'wb') as fileWriteStream:\n",
    "    pickle.dump(all_data_model, fileWriteStream)\n",
    "    # Don't forget to close the filestream!\n",
    "    fileWriteStream.close()\n",
    "    \n",
    "print('pickle file of Predictive Model is saved at Location:',os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FunctionPredictResult(InputData):\n",
    "    import pandas as pd\n",
    "    Num_Inputs=InputData.shape[0]\n",
    "    \n",
    "    # Making sure the input data has same columns as it was used for training the model\n",
    "    # Also, if standardization/normalization was done, then same must be done for new input\n",
    "    \n",
    "    # Appending the new data with the Training data\n",
    "    DataForML=pd.read_pickle('DataForML.pkl')\n",
    "    InputData=InputData.append(DataForML)\n",
    "\n",
    "            \n",
    "    # Maintaining the same order of columns as it was during the model training\n",
    "    Predictors=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT',]\n",
    "    \n",
    "    # Generating the input values to the model\n",
    "    X=InputData[Predictors].values[0:Num_Inputs]\n",
    "    \n",
    "    # Generating the standardized values of X since it was done while model training also\n",
    "    X=PredictorScalerFit.transform(X)\n",
    "    \n",
    "    # Loading the Function from pickle file\n",
    "    import pickle\n",
    "    with open('Final_Model.pkl', 'rb') as fileReadStream:\n",
    "        PredictionModel=pickle.load(fileReadStream)\n",
    "        # Don't forget to close the filestream!\n",
    "        fileReadStream.close()\n",
    "            \n",
    "    # Genrating Predictions\n",
    "    Prediction=PredictionModel.predict(X)\n",
    "    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n",
    "    return(PredictionResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CRIM       ZN  INDUS  CHAS  NOX     RM    AGE   DIS     RAD  TAX  PTRATIO  \\\n",
      "0    10  0.22489   12.5  7.87    0  0.524  6.377  94.3  6.3467    5    311.0   \n",
      "1    10  0.22489   12.5  7.87    0  0.524  6.377  94.3  6.3467    5    311.0   \n",
      "\n",
      "      B   LSTAT  \n",
      "0  15.2  392.52  \n",
      "1  15.2  392.52  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/dhbmym6s0gb3_qp1wrvjs0rr0000gn/T/ipykernel_90267/1479496327.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  InputData=InputData.append(DataForML)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-474.647069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-474.647069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0 -474.647069\n",
       "1 -474.647069"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewSampleData=pd.DataFrame(\n",
    "data=[[10,0.22489,12.5,7.87,0,0.524,6.377,94.3,6.3467,5,311.0,15.2,392.52],\n",
    "     [10,0.22489,12.5,7.87,0,0.524,6.377,94.3,6.3467,5,311.0,15.2,392.52]],\n",
    "columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT',])\n",
    "\n",
    "print(NewSampleData)\n",
    "\n",
    "# Calling the Function for prediction\n",
    "FunctionPredictResult(InputData= NewSampleData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/dhbmym6s0gb3_qp1wrvjs0rr0000gn/T/ipykernel_90267/1479496327.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  InputData=InputData.append(DataForML)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-30.27832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0   -30.27832"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the function which can take inputs and return prediction\n",
    "def FunctionGeneratePrediction(inp_LSTAT , inp_RM, inp_PTRATIO, inp_CRIM, inp_ZN, inp_INDUS, inp_CHAS, inp_NOX, inp_AGE, inp_DIS, inp_RAD, inp_TAX, inp_B):\n",
    "    \n",
    "    # Creating a data frame for the model input\n",
    "    SampleInputData=pd.DataFrame(data=[[inp_CRIM, inp_ZN, inp_INDUS, inp_CHAS, inp_NOX, inp_AGE, inp_DIS, inp_RAD, inp_TAX, inp_B, inp_LSTAT , inp_RM, inp_PTRATIO]],\n",
    "    columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'])\n",
    "\n",
    "    # Calling the function defined above using the input parameters\n",
    "    Predictions=FunctionPredictResult(InputData= SampleInputData)\n",
    "    return(Predictions)\n",
    "\n",
    "    # Returning the predictions;\n",
    "    return(Predictions.to_json())\n",
    "\n",
    "# Function call\n",
    "FunctionGeneratePrediction(inp_CRIM =0.5 ,inp_ZN=6.78, inp_INDUS = 6.56, inp_CHAS=5.6, inp_NOX=4.6, inp_AGE=7.9, inp_DIS = 544.3 , inp_RAD=21.56, inp_TAX = 43.56, inp_B = 5.6, inp_LSTAT=4.98,inp_RM=6.5,inp_PTRATIO=15.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e985290a6e02f6c7d3dda52d73c6aeb9d047005ca0660c6a065b6c58e39b6dd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
